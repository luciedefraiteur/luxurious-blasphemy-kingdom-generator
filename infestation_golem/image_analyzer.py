#!/usr/bin/env python3
"""
üîÆ IMAGE ANALYZER - Analyse d'images via BLIP-2 pour fractale r√©cursive
‚õßùñö‚üÅ‚áå‚ÜØ‚ü≤‚±∑ìÇÄìÜ©‚´∑ùñãùñÜùñéùñóùñäùñàùñçùñô‚õßñ§êùîê

Analyse automatique des sigils et images g√©n√©r√©es pour la fractale r√©cursive
"""

import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
import torch
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration
import argparse

class ImageAnalyzer:
    def __init__(self, model_name: str = "Salesforce/blip2-opt-2.7b"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üîÆ Initialisation ImageAnalyzer sur {self.device}")
        
        # Charger le mod√®le BLIP-2
        print("üì¶ Chargement du mod√®le BLIP-2...")
        self.processor = Blip2Processor.from_pretrained(model_name)
        self.model = Blip2ForConditionalGeneration.from_pretrained(
            model_name, 
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        )
        self.model.to(self.device)
        print("‚úÖ Mod√®le BLIP-2 charg√© avec succ√®s")
        
        self.analysis_results = []
        
    def analyze_image(self, image_path: Path, custom_prompt: Optional[str] = None) -> Dict[str, Any]:
        """Analyser une image avec BLIP-2"""
        try:
            # Charger l'image
            image = Image.open(image_path).convert('RGB')
            
            # Pr√©parer les prompts
            prompts = [
                "Describe this image in detail:",
                "What symbols, shapes, and mystical elements do you see?",
                "Describe the artistic style and mood:",
                "What occult or esoteric symbols are present?"
            ]
            
            if custom_prompt:
                prompts.append(custom_prompt)
            
            results = {}
            
            for prompt in prompts:
                # Traiter l'image avec le prompt
                inputs = self.processor(image, prompt, return_tensors="pt").to(self.device)
                
                # G√©n√©rer la description
                with torch.no_grad():
                    generated_ids = self.model.generate(**inputs, max_length=100, num_beams=5)
                
                # D√©coder la r√©ponse
                generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                
                # Nettoyer la r√©ponse (enlever le prompt)
                if prompt in generated_text:
                    generated_text = generated_text.replace(prompt, "").strip()
                
                # Stocker le r√©sultat
                prompt_key = prompt.replace(":", "").replace(" ", "_").lower()
                results[prompt_key] = generated_text
            
            # M√©tadonn√©es
            analysis = {
                "file_path": str(image_path),
                "file_name": image_path.name,
                "file_size": image_path.stat().st_size,
                "analysis_timestamp": time.time(),
                "device_used": self.device,
                "descriptions": results,
                "combined_description": self._combine_descriptions(results)
            }
            
            print(f"‚úÖ Analys√©: {image_path.name}")
            return analysis
            
        except Exception as e:
            print(f"‚ùå Erreur analyse {image_path}: {e}")
            return {
                "file_path": str(image_path),
                "file_name": image_path.name,
                "error": str(e),
                "analysis_timestamp": time.time()
            }
    
    def _combine_descriptions(self, descriptions: Dict[str, str]) -> str:
        """Combiner toutes les descriptions en une seule"""
        combined = []
        for key, desc in descriptions.items():
            if desc and desc.strip():
                combined.append(desc.strip())
        
        return " | ".join(combined)
    
    def analyze_directory(self, directory: Path, extensions: List[str] = None) -> List[Dict[str, Any]]:
        """Analyser tous les images d'un dossier"""
        if extensions is None:
            extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
        
        print(f"üìÅ Analyse du dossier: {directory}")
        
        # Trouver toutes les images
        image_files = []
        for ext in extensions:
            image_files.extend(directory.glob(f"*{ext}"))
            image_files.extend(directory.glob(f"*{ext.upper()}"))
        
        print(f"üñºÔ∏è {len(image_files)} images trouv√©es")
        
        results = []
        for i, image_file in enumerate(image_files, 1):
            print(f"üîç Analyse {i}/{len(image_files)}: {image_file.name}")
            
            analysis = self.analyze_image(image_file)
            results.append(analysis)
            
            # Petite pause pour √©viter la surchauffe
            time.sleep(0.5)
        
        self.analysis_results.extend(results)
        return results
    
    def save_results(self, output_file: Path):
        """Sauvegarder les r√©sultats d'analyse"""
        output_data = {
            "analysis_metadata": {
                "total_images": len(self.analysis_results),
                "analysis_date": time.strftime("%Y-%m-%d %H:%M:%S"),
                "device_used": self.device,
                "model_used": "Salesforce/blip2-opt-2.7b"
            },
            "analyses": self.analysis_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ R√©sultats sauv√©s: {output_file}")
    
    def analyze_sigils(self, sigils_dir: str = "/home/luciedefraiteur/T√©l√©chargements/sygils") -> List[Dict[str, Any]]:
        """Analyser sp√©cifiquement les sigils existants"""
        sigils_path = Path(sigils_dir)
        
        if not sigils_path.exists():
            print(f"‚ùå Dossier sigils non trouv√©: {sigils_dir}")
            return []
        
        print("üîÆ ANALYSE DES SIGILS EXISTANTS")
        print("‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß‚õß")
        
        # Analyser avec des prompts sp√©cialis√©s pour sigils
        results = []
        image_files = []
        
        # Chercher les images
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend(sigils_path.glob(f"*{ext}"))
            image_files.extend(sigils_path.glob(f"*{ext.upper()}"))
        
        print(f"üîÆ {len(image_files)} sigils trouv√©s")
        
        for i, sigil_file in enumerate(image_files, 1):
            print(f"‚õß Analyse sigil {i}/{len(image_files)}: {sigil_file.name}")
            
            # Analyse sp√©cialis√©e pour sigils
            analysis = self.analyze_sigil(sigil_file)
            results.append(analysis)
        
        return results
    
    def analyze_sigil(self, sigil_path: Path) -> Dict[str, Any]:
        """Analyse sp√©cialis√©e pour un sigil"""
        try:
            image = Image.open(sigil_path).convert('RGB')
            
            # Prompts sp√©cialis√©s pour sigils
            sigil_prompts = [
                "Describe this mystical symbol or sigil:",
                "What geometric patterns and shapes are present?",
                "Describe any occult, esoteric, or magical symbols:",
                "What is the overall energy and mood of this sigil?",
                "Describe the lines, curves, and symbolic elements:"
            ]
            
            results = {}
            
            for prompt in sigil_prompts:
                inputs = self.processor(image, prompt, return_tensors="pt").to(self.device)
                
                with torch.no_grad():
                    generated_ids = self.model.generate(**inputs, max_length=120, num_beams=5)
                
                generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
                
                # Nettoyer
                if prompt in generated_text:
                    generated_text = generated_text.replace(prompt, "").strip()
                
                prompt_key = prompt.replace(":", "").replace(" ", "_").replace("?", "").lower()
                results[prompt_key] = generated_text
            
            # Analyse sp√©cialis√©e
            analysis = {
                "file_path": str(sigil_path),
                "file_name": sigil_path.name,
                "file_size": sigil_path.stat().st_size,
                "analysis_timestamp": time.time(),
                "type": "sigil",
                "device_used": self.device,
                "sigil_descriptions": results,
                "combined_sigil_description": self._combine_descriptions(results),
                "magical_keywords": self._extract_magical_keywords(results)
            }
            
            return analysis
            
        except Exception as e:
            print(f"‚ùå Erreur analyse sigil {sigil_path}: {e}")
            return {
                "file_path": str(sigil_path),
                "file_name": sigil_path.name,
                "error": str(e),
                "type": "sigil",
                "analysis_timestamp": time.time()
            }
    
    def _extract_magical_keywords(self, descriptions: Dict[str, str]) -> List[str]:
        """Extraire des mots-cl√©s magiques des descriptions"""
        magical_words = [
            "circle", "triangle", "pentagram", "hexagram", "spiral", "rune", "symbol",
            "mystical", "occult", "esoteric", "magical", "sacred", "divine", "cosmic",
            "energy", "power", "ritual", "spell", "enchantment", "sigil", "talisman",
            "geometric", "pattern", "mandala", "chakra", "aura", "spiritual", "astral"
        ]
        
        found_keywords = []
        combined_text = " ".join(descriptions.values()).lower()
        
        for word in magical_words:
            if word in combined_text:
                found_keywords.append(word)
        
        return found_keywords

def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(description="üîÆ Image Analyzer - Analyse d'images via BLIP-2")
    
    parser.add_argument("--sigils", action="store_true", help="Analyser les sigils existants")
    parser.add_argument("--directory", type=str, help="Analyser un dossier sp√©cifique")
    parser.add_argument("--image", type=str, help="Analyser une image sp√©cifique")
    parser.add_argument("--output", type=str, default="analysis_results.json", help="Fichier de sortie")
    
    args = parser.parse_args()
    
    # Initialiser l'analyseur
    analyzer = ImageAnalyzer()
    
    if args.sigils:
        # Analyser les sigils
        results = analyzer.analyze_sigils()
        analyzer.analysis_results = results
        
    elif args.directory:
        # Analyser un dossier
        directory = Path(args.directory)
        if directory.exists():
            analyzer.analyze_directory(directory)
        else:
            print(f"‚ùå Dossier non trouv√©: {args.directory}")
            return
            
    elif args.image:
        # Analyser une image
        image_path = Path(args.image)
        if image_path.exists():
            result = analyzer.analyze_image(image_path)
            analyzer.analysis_results = [result]
        else:
            print(f"‚ùå Image non trouv√©e: {args.image}")
            return
    else:
        print("üîÆ Utilisation:")
        print("  --sigils : Analyser les sigils existants")
        print("  --directory [path] : Analyser un dossier")
        print("  --image [path] : Analyser une image")
        return
    
    # Sauvegarder les r√©sultats
    output_path = Path(args.output)
    analyzer.save_results(output_path)
    
    print(f"\n‚úÖ Analyse termin√©e - {len(analyzer.analysis_results)} images analys√©es")
    print(f"üíæ R√©sultats dans: {output_path}")

if __name__ == "__main__":
    main()
